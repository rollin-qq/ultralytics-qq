# Ultralytics YOLO ğŸš€, GPL-3.0 license
import sys

import torch

from ultralytics.yolo.engine.predictor import BasePredictor
from ultralytics.yolo.engine.results import Results
from ultralytics.yolo.utils import DEFAULT_CFG, ROOT, ops
from ultralytics.yolo.utils.plotting import Annotator, colors, save_one_box


class DetectionPredictor(BasePredictor):

    def get_annotator(self, img):
        return Annotator(img, line_width=self.args.line_thickness, example=str(self.model.names))

    def preprocess(self, img):
        img = torch.from_numpy(img).to(self.model.device)
        img = img.half() if self.model.fp16 else img.float()  # uint8 to fp16/32
        img /= 255  # 0 - 255 to 0.0 - 1.0
        return img

    def postprocess(self, preds, img, orig_img, classes=None):
        preds = ops.non_max_suppression(preds,
                                        self.args.conf,
                                        self.args.iou,
                                        agnostic=self.args.agnostic_nms,
                                        max_det=self.args.max_det,
                                        classes=self.args.classes)

        results = []
        for i, pred in enumerate(preds):
            shape = orig_img[i].shape if isinstance(orig_img, list) else orig_img.shape
            pred[:, :4] = ops.scale_boxes(img.shape[2:], pred[:, :4], shape).round()
            results.append(Results(boxes=pred, orig_shape=shape[:2]))
        return results


    #å¯¹ä¸€ä¸ªbatchä¸­çš„æ•°æ®è¿›è¡Œå¤„ç†å¹¶è¾“å‡ºæ—¥å¿—ä¿¡æ¯
    def write_results(self, idx, results, batch):
        p, im, im0 = batch
        log_string = ""
        #åˆ¤æ–­imçš„ç»´åº¦æ˜¯å¦ä¸º3ï¼Œå¦‚æœä¸æ˜¯åˆ™åœ¨ç¬¬ä¸€ç»´ä¸Šæ‰©å±•ä¸€ç»´ï¼Œç”¨äºè¡¨ç¤ºbatchå¤§å°
        if len(im.shape) == 3:
            im = im[None]  # expand for batch dim
        self.seen += 1
        imc = im0.copy() if self.args.save_crop else im0
        if self.source_type.webcam or self.source_type.from_img:  # batch_size >= 1
            log_string += f'{idx}: '
            frame = self.dataset.count
        else:
            frame = getattr(self.dataset, 'frame', 0)
        #å°†å½“å‰å›¾åƒæ•°æ®çš„è·¯å¾„ p èµ‹å€¼ç»™å®ä¾‹å˜é‡ self.data_pathï¼Œå¹¶æ ¹æ®æ•°æ®é›†çš„æ¨¡å¼ï¼ˆimage æˆ– videoï¼‰ä»¥åŠå½“å‰å¸§æ•°ï¼ˆå¦‚æœæ˜¯è§†é¢‘ï¼‰æ„é€ æ ‡ç­¾æ–‡ä»¶çš„è·¯å¾„ self.txt_pathã€‚
        self.data_path = p
        self.txt_path = str(self.save_dir / 'labels' / p.stem) + ('' if self.dataset.mode == 'image' else f'_{frame}')
        #åœ¨æ—¥å¿—å­—ç¬¦ä¸² log_string çš„æœ«å°¾æ·»åŠ å½“å‰å›¾åƒæ•°æ®çš„å°ºå¯¸ä¿¡æ¯ã€‚
        log_string += '%gx%g ' % im.shape[2:]  # print string
        self.annotator = self.get_annotator(im0)

        det = results[idx].boxes  # TODO: make boxes inherit from tensors
        if len(det) == 0:
            return log_string
        for c in det.cls.unique():
            n = (det.cls == c).sum()  # detections per class
            log_string += f"{n} {self.model.names[int(c)]}{'s' * (n > 1)}, "

        # write
        for d in reversed(det):
            cls, conf = d.cls.squeeze(), d.conf.squeeze()
            if self.args.save_txt:  # Write to file
                line = (cls, *(d.xywhn.view(-1).tolist()), conf) \
                    if self.args.save_conf else (cls, *(d.xywhn.view(-1).tolist()))  # label format
                with open(f'{self.txt_path}.txt', 'a') as f:
                    f.write(('%g ' * len(line)).rstrip() % line + '\n')
            if self.args.save or self.args.save_crop or self.args.show:  # Add bbox to image
                c = int(cls)  # integer class
                label = None if self.args.hide_labels else (
                    self.model.names[c] if self.args.hide_conf else f'{self.model.names[c]} {conf:.2f}')
                self.annotator.box_label(d.xyxy.squeeze(), label, color=colors(c, True))
            if self.args.save_crop:
                save_one_box(d.xyxy,
                             imc,
                             file=self.save_dir / 'crops' / self.model.model.names[c] / f'{self.data_path.stem}.jpg',
                             BGR=True)

        return log_string


def predict(cfg=DEFAULT_CFG, use_python=False):
    #ä»é…ç½®æ–‡ä»¶(cfg)ä¸­è·å–æ¨¡å‹åç§°ï¼Œå¦‚æœæ²¡æœ‰è®¾ç½®åˆ™é»˜è®¤ä½¿ç”¨"yolov8n.pt"æ¨¡å‹
    model = cfg.model or "yolov8n.pt"
    #ä»é…ç½®æ–‡ä»¶ä¸­è·å–å›¾åƒæ•°æ®æº(source)ï¼Œå¦‚æœæ²¡æœ‰è®¾ç½®åˆ™æŸ¥çœ‹assetsæ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨ï¼Œè‹¥å­˜åœ¨åˆ™å°†å…¶ä½œä¸ºæ•°æ®æºï¼Œ
    #å¦åˆ™ä½¿ç”¨"https://ultralytics.com/images/bus.jpg"ä½œä¸ºæ•°æ®æºã€‚
    source = cfg.source if cfg.source is not None else ROOT / "assets" if (ROOT / "assets").exists() \
        else "https://ultralytics.com/images/bus.jpg"


    #å°†æ¨¡å‹å’Œæ•°æ®æºä»¥å­—å…¸(args)å½¢å¼ä¼ å…¥ï¼Œæ ¹æ®use_pythonå‚æ•°åˆ¤æ–­æ˜¯å¦ä½¿ç”¨ultralyticsåŒ…ä¸­çš„YOLOç±»è¿›è¡Œé¢„æµ‹ï¼Œ
    #è¿˜æ˜¯ä½¿ç”¨DetectionPredictorç±»è¿›è¡Œé¢„æµ‹å¹¶åœ¨å‘½ä»¤è¡Œç•Œé¢æ˜¾ç¤ºç»“æœã€‚
    args = dict(model=model, source=source)
    if use_python:
        from ultralytics import YOLO
        YOLO(model)(**args)
    else:
        predictor = DetectionPredictor(overrides=args)
        predictor.predict_cli()


if __name__ == "__main__":
    predict()
